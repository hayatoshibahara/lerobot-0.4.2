{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63c27d7e",
   "metadata": {},
   "source": [
    "# ACTモデルの訓練"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fae66f3",
   "metadata": {},
   "source": [
    "## 概要\n",
    "\n",
    "作成したデータセットを使用し、[ACTモデル][1]を訓練する。\n",
    "\n",
    "[ACTモデルの解説][2]\n",
    "\n",
    "[1]: https://huggingface.co/docs/lerobot/en/act\n",
    "[2]: https://github.com/hayatoshibahara/act/blob/main/main.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c145ec70",
   "metadata": {},
   "source": [
    "## 環境構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fbed74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 環境変数の取得\n",
    "\n",
    "try: \n",
    "    # Google Colabの場合\n",
    "    from google.colab import userdata\n",
    "    IS_COLAB = True\n",
    "    HF_USER = userdata.get(\"HF_USER\")\n",
    "    HF_TOKEN = userdata.get(\"HF_TOKEN\")\n",
    "    WANDB_API_KEY = userdata.get(\"WANDB_API_KEY\")\n",
    "    import os\n",
    "    os.environ[\"HF_USER\"] = HF_USER\n",
    "    os.environ[\"HF_TOKEN\"] = HF_TOKEN\n",
    "    os.environ[\"WANDB_API_KEY\"] = WANDB_API_KEY\n",
    "except:\n",
    "    # ローカル環境の場合\n",
    "    from dotenv import load_dotenv\n",
    "    IS_COLAB = False\n",
    "    import os\n",
    "    load_dotenv()\n",
    "    HF_USER = os.getenv(\"HF_USER\")\n",
    "    HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "    WANDB_API_KEY = os.getenv(\"WANDB_API_KEY\")\n",
    "\n",
    "assert HF_USER\n",
    "assert HF_TOKEN\n",
    "assert WANDB_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c7647e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conda環境のセットアップ\n",
    "\n",
    "try:\n",
    "    import condacolab\n",
    "except:\n",
    "    %pip install -q condacolab\n",
    "    import condacolab\n",
    "    condacolab.install()\n",
    "\n",
    "# 初回はここで再起動"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe693d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wandbのログイン\n",
    "\n",
    "import wandb\n",
    "wandb.login(key=WANDB_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39755cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LeRobotのインストール\n",
    "\n",
    "if IS_COLAB:\n",
    "    import os\n",
    "    if not os.path.exists(\"/content/lerobot\"):\n",
    "        !git clone -b v0.4.2 --depth 1 https://github.com/huggingface/lerobot.git\n",
    "    %cd /content/lerobot\n",
    "    %pip install -e .\n",
    "else:\n",
    "    import os\n",
    "    if not os.path.exists(\"/workspace/lerobot\"):\n",
    "        !git clone -b v0.4.2 --depth 1 https://github.com/huggingface/lerobot.git\n",
    "    %cd /workspace/lerobot\n",
    "    %pip install -e .\n",
    "\n",
    "import lerobot\n",
    "%pip show lerobot\n",
    "\n",
    "# 初回はここで強制再起動"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68c4ab2",
   "metadata": {},
   "source": [
    "## 訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea2c707",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "DATETIME = now.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "os.environ[\"DATETIME\"] = DATETIME\n",
    "\n",
    "# 使用するデータセット名（注意: 要変更）\n",
    "DATASET_REPO_NAME = \"your-dataset-repo-name\"\n",
    "os.environ[\"DATASET_REPO_NAME\"] = DATASET_REPO_NAME\n",
    "\n",
    "OUTPUT_DIR = f\"{DATASET_REPO_NAME}_act_{DATETIME}\"\n",
    "JOB_NAME = f\"{DATASET_REPO_NAME}_act_{DATETIME}\"\n",
    "POLICY_REPO_NAME = f\"{DATASET_REPO_NAME}_act_{DATETIME}\"\n",
    "\n",
    "# バッチサイズ（注意: 要調整）\n",
    "# メモリ不足が発生する場合は下げ、逆に余裕がある場合は上げる\n",
    "# 1, 2, 4, 8, 16, 32, 64...など2の累乗が一般的\n",
    "# 例: A100の場合はバッチサイズ8で5/40GBで余裕あり、バッチサイズ32でも動作しそう\n",
    "# 例: H100の場合はバッチサイズ64で30.2GB/80GBで余裕があり、バッチサイズ128でも動作しそう\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "COMMAND = f\"lerobot-train \\\n",
    "    --batch_size={BATCH_SIZE} \\\n",
    "    --job_name={JOB_NAME} \\\n",
    "    --log_freq=100 \\\n",
    "    --num_workers=0 \\\n",
    "    --resume=false \\\n",
    "    --save_freq=1000 \\\n",
    "    --steps=200_000 \\\n",
    "    --output_dir={OUTPUT_DIR} \\\n",
    "    --dataset.repo_id={HF_USER}/{DATASET_REPO_NAME} \\\n",
    "    --policy.device=cuda \\\n",
    "    --policy.repo_id={HF_USER}/{POLICY_REPO_NAME} \\\n",
    "    --policy.type=act \\\n",
    "    --wandb.enable=true\"\n",
    "\n",
    "print(COMMAND)\n",
    "\n",
    "# コマンドを実行\n",
    "# バッチサイズを上げると1ステップあたりの処理時間が長くなるが、学習の進みは早くなる\n",
    "# 学習の進捗はWandbのダッシュボードで確認し、train/lossが収束したら学習を停止する\n",
    "!$COMMAND\n",
    "\n",
    "# より汎化性能を高めたい場合はdataset.image_transformsオプションを使用して画像変換を追加する\n",
    "# https://huggingface.co/docs/lerobot/en/lerobot-dataset-v3#image-transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5799ca81",
   "metadata": {},
   "source": [
    "コマンドライン引数の説明は、`src/lerobot/configs/train.py`にある。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e57ea8",
   "metadata": {},
   "source": [
    "一般的な設定\n",
    "\n",
    "| フィールド名 | 型 | デフォルト値 | 説明 |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| `dataset` | `DatasetConfig` | (必須) | データセット設定。 |\n",
    "| `env` | `envs.EnvConfig \\| None` | `None` | 環境設定。 |\n",
    "| `policy` | `PreTrainedConfig \\| None` | `None` | ポリシー設定。 |\n",
    "| `output_dir` | `Path \\| None` | `None` | 実行時の全出力を保存するディレクトリ。<br>`resume`を`True`に設定しない限り、同じディレクトリで別のトレーニングセッションを実行すると、内容は上書きされます。 |\n",
    "| `job_name` | `str \\| None` | `None` | ジョブ名。 |\n",
    "| `resume` | `bool` | `False` | 以前の実行を再開するかどうか。<br>再開するには、`output_dir`が少なくとも1つのチェックポイントを含む既存の実行ディレクトリである必要があります。<br>再開時、コマンドライン引数に関わらず、チェックポイント内の設定がデフォルトで使用されることに注意してください。 |\n",
    "| `seed` | `int \\| None` | `1000` | トレーニング（モデル初期化、データセットのシャッフルなど）および評価環境で使用されるシード値。 |\n",
    "| `num_workers` | `int` | `4` | データローダーで使用するワーカー数。 |\n",
    "| `batch_size` | `int` | `8` | バッチサイズ。 |\n",
    "| `steps` | `int` | `100_000` | トレーニングを行う総ステップ数。 |\n",
    "| `eval_freq` | `int` | `20_000` | 評価を実行する頻度（ステップ数）。 |\n",
    "| `log_freq` | `int` | `200` | ログを記録する頻度（ステップ数）。 |\n",
    "| `save_checkpoint` | `bool` | `True` | チェックポイントを保存するかどうか。 |\n",
    "| `save_freq` | `int` | `20_000` | チェックポイントを保存する頻度（ステップ数）。最後のトレーニングステップ後にも保存されます。 |\n",
    "| `use_policy_training_preset` | `bool` | `True` | ポリシー固有のトレーニングプリセット（推奨されるオプティマイザ設定など）を使用するかどうか。 |\n",
    "| `optimizer` | `OptimizerConfig \\| None` | `None` | オプティマイザ設定。 |\n",
    "| `scheduler` | `LRSchedulerConfig \\| None` | `None` | 学習率スケジューラ設定。 |\n",
    "| `eval` | `EvalConfig` | `EvalConfig()` | 評価設定。 |\n",
    "| `wandb` | `WandBConfig` | `WandBConfig()` | Weights & Biasesの設定。 |\n",
    "| `checkpoint_path` | `Path \\| None` | `None` | （内部使用）再開時に使用されるチェックポイントのパス。初期化時は `None`。 |\n",
    "| `rename_map` | `dict[str, str]` | `{}` | 観測データ（画像や状態のキー）を上書きするためのリネームマップ。 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b40c2ec",
   "metadata": {},
   "source": [
    "データセットの設定（DatasetConfig）\n",
    "\n",
    "| フィールド名 | 型 | デフォルト値 | 説明 |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| `repo_id` | `str` | (必須) | データセットのリポジトリID。データセットのリストを指定することもでき、その場合 `train.py` がそれらを連結します。<br>注意: データセット間で共通するデータキーのみが保持されます。各データセットには、返されるアイテムに \"dataset_index\" を挿入する追加の変換処理が適用され、インデックスの割り当てはデータセットの指定順に基づいて行われます。 |\n",
    "| `root` | `str \\| None` | `None` | データセットが保存されるルートディレクトリ（例: `dataset/path`）。 |\n",
    "| `episodes` | `list[int] \\| None` | `None` | 使用するエピソードのリスト。 |\n",
    "| `image_transforms` | `ImageTransformsConfig` | `ImageTransformsConfig()` | 画像変換設定。 |\n",
    "| `revision` | `str \\| None` | `None` | データセットのリビジョン（バージョン）。 |\n",
    "| `use_imagenet_stats` | `bool` | `True` | ImageNetの統計情報（平均・標準偏差）を使用するかどうか。 |\n",
    "| `video_backend` | `str` | *システム依存* | 動画の読み込みに使用するバックエンド（例: `pyav`, `opencv`）。 |\n",
    "| `streaming` | `bool` | `False` | ストリーミングモード（データを全てダウンロードせずに逐次読み込む）を使用するかどうか。 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5eff3c9",
   "metadata": {},
   "source": [
    "環境設定（EnvConfig）\n",
    "\n",
    "| フィールド名 | 型 | デフォルト値 | 説明 |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| `task` | `str \\| None` | `None` | タスクの名称。 |\n",
    "| `fps` | `int` | `30` | 1秒あたりのフレーム数（FPS）。 |\n",
    "| `features` | `dict[str, PolicyFeature]` | `{}` | 環境が提供する特徴量（観測やアクションなど）の定義。 |\n",
    "| `features_map` | `dict[str, str]` | `{}` | 特徴量の名前マッピング。 |\n",
    "| `max_parallel_tasks` | `int` | `1` | 並行して実行するタスクの最大数。 |\n",
    "| `disable_env_checker` | `bool` | `True` | Gymの環境チェッカーを無効にするかどうか。 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0186cc",
   "metadata": {},
   "source": [
    "事前学習済みモデルの設定（PreTrainedConfig）\n",
    "\n",
    "| フィールド名 | 型 | デフォルト値 | 説明 |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| `n_obs_steps` | `int` | `1` | ポリシーに渡す観測データの環境ステップ数（現在のステップと、過去に遡る追加ステップを含みます）。 |\n",
    "| `input_features` | `dict[str, PolicyFeature]` | `{}` | ポリシーへの入力データの定義。 |\n",
    "| `output_features` | `dict[str, PolicyFeature]` | `{}` | ポリシーからの出力データの定義。 |\n",
    "| `device` | `str \\| None` | `None` | 使用するデバイス（例: \"cuda\", \"cuda:0\", \"cpu\", \"mps\"）。 |\n",
    "| `use_amp` | `bool` | `False` | トレーニングおよび評価でAutomatic Mixed Precision (AMP)を使用するかどうかを決定します。AMPを使用すると、自動勾配スケーリングが有効になります。 |\n",
    "| `push_to_hub` | `bool` | `True` | モデルをHugging Face Hubにアップロードするかどうか。 |\n",
    "| `repo_id` | `str \\| None` | `None` | Hugging Face HubのリポジトリID。 |\n",
    "| `private` | `bool \\| None` | `None` | Hugging Face Hubのプライベートリポジトリにアップロードするかどうか。 |\n",
    "| `tags` | `list[str] \\| None` | `None` | Hub上のポリシーに追加するタグのリスト。 |\n",
    "| license | `str \\| None` | `None` | ライセンス情報。 |\n",
    "| `pretrained_path` | `Path \\| None` | `None` | HubでホストされているモデルのリポジトリID、または `Policy.save_pretrained` を使用して保存された重みを含むディレクトリへのパス。<br>指定されない場合、ポリシーはスクラッチから初期化されます。 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3806516b",
   "metadata": {},
   "source": [
    "オプティマイザの設定（OptimizerConfig）\n",
    "\n",
    "| フィールド名 | 型 | 説明 |\n",
    "| :--- | :--- | :--- |\n",
    "| `lr` | `float` | 学習率（Learning Rate）。 |\n",
    "| `weight_decay` | `float` | 重み減衰（Weight Decay）。過学習を防ぐための正則化項です。 |\n",
    "| `grad_clip_norm` | `float` | 勾配クリッピングのノルム値。勾配爆発を防ぐために勾配のノルムをこの値に制限します。 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25aa9dcf",
   "metadata": {},
   "source": [
    "学習スケージューラの設定（LRSchedulerConfig）\n",
    "\n",
    "| フィールド名 | 型 | 説明 |\n",
    "| :--- | :--- | :--- |\n",
    "| `num_warmup_steps` | `int` | ウォームアップステップ数。学習率を0から初期学習率まで徐々に上げていく期間のステップ数です。 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4286db",
   "metadata": {},
   "source": [
    "Weight and Biases の設定（WandbConfig）\n",
    "\n",
    "| フィールド名 | 型 | デフォルト値 | 説明 |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| `enable` | `bool` | `False` | Weights & Biases (WandB) のログ記録を有効にするかどうか。 |\n",
    "| `disable_artifact` | `bool` | `False` | `training.save_checkpoint=True` であっても、アーティファクトの保存を無効にする場合は `True` に設定します。 |\n",
    "| `project` | `str` | `\"lerobot\"` | WandBのプロジェクト名。 |\n",
    "| `entity` | `str \\| None` | `None` | WandBのエンティティ（ユーザー名またはチーム名）。 |\n",
    "| `notes` | `str \\| None` | `None` | 実行に関するメモ。 |\n",
    "| `run_id` | `str \\| None` | `None` | 実行ID。以前の実行を特定して再開する場合などに使用します。 |\n",
    "| `mode` | `str \\| None` | `None` | 実行モード（許可される値: `'online'`, `'offline'`, `'disabled'`）。デフォルトは `'online'` です。 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e498a0",
   "metadata": {},
   "source": [
    "## トラッキング\n",
    "\n",
    "Wandbで訓練損失をトラッキングできる。\n",
    "\n",
    "損失の変動が落ち着くまで訓練を続ける（以下の場合は20kで早期終了する）。\n",
    "\n",
    "バッチサイズ8、50エピソードのデータセットで、A100を使用して訓練すると1時間20分程度で完了する。\n",
    "\n",
    "![](asset/trained.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d302b9",
   "metadata": {},
   "source": [
    "## 非同期アップロード\n",
    "\n",
    "Google Colabでターミナルを開き、訓練中のモデルをアップロードできる。\n",
    "\n",
    "```sh\n",
    "# トークンを設定\n",
    "HF_USER=\"...\"\n",
    "HF_TOKEN=\"...\"\n",
    "\n",
    "# 第2引数はアップロード先のリポジトリIDを選択する\n",
    "# 第3引数はアップロードしたいモデルのパスを選択する\n",
    "hf upload \\\n",
    "    --token $HF_TOKEN \\\n",
    "    $HF_USER/grab-a-cube_act_2026-01-17-06-56-00_001000 \\\n",
    "    lerobot/your_model_name/checkpoints/$NUM_STEPS/pretrained_model\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa79d5a7",
   "metadata": {},
   "source": [
    "## 事前学習済みモデルのファインチューニング\n",
    "\n",
    "```sh\n",
    "!lerobot-train \\\n",
    "    --dataset.repo_id=EngineerCafeJP/record-test-2025-08-26-21-21-00 \\\n",
    "    --policy.path=EngineerCafeJP/act-so101-test \\\n",
    "    --policy.push_to_hub=true \\\n",
    "    --policy.repo_id=EngineerCafeJP/act-so101-test-2025-08-26-21-21-00 \\\n",
    "    --output_dir=act_output \\\n",
    "    --job_name=act_so101_test_2025-08-26-21-21-00 \\\n",
    "    --resume=false \\\n",
    "    --num_workers=0 \\\n",
    "    --batch_size=8 \\\n",
    "    --steps=20000 \\\n",
    "    --save_freq=2000 \\\n",
    "    --wandb.enable=true\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
